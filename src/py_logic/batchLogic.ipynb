{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import boto3\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa8cfc",
   "metadata": {},
   "source": [
    "# Settings - Logica para validar los settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_settings(outputs, settings):\n",
    "    if not settings or len(settings) == 0:\n",
    "        return outputs[0]\n",
    "    \n",
    "    filter_outputs = outputs[0]\n",
    "    \n",
    "    for element in settings:\n",
    "        if element[\"key\"] == \"outputs_per_user\":\n",
    "            filter_outputs = outputs[0][:element[\"value\"]]\n",
    "            break\n",
    "    \n",
    "    return filter_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1704d89",
   "metadata": {},
   "source": [
    "# Metricas - Logica para extraer Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_metrics(metrics, user_data):\n",
    "    data = {}\n",
    "\n",
    "    if not metrics or len(metrics) == 0:\n",
    "        return data\n",
    "\n",
    "    await asyncio.gather(*[\n",
    "        asyncio.create_task(assign_data(metric, data, user_data))\n",
    "        for metric in metrics\n",
    "    ])\n",
    "\n",
    "    return data\n",
    "\n",
    "async def assign_data(metric, data, user_data):\n",
    "    data[metric['key']] = user_data[metric['key']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1210db8",
   "metadata": {},
   "source": [
    "# Segmento - Logica para extraer Usuarios de S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629faa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_user_from_bucket(path):\n",
    "    try:\n",
    "        if path is None:\n",
    "            return []\n",
    "\n",
    "        s3 = boto3.client('s3')\n",
    "        data = path.split(\"//\")\n",
    "        bucket = data[1].split(\"/\")[0]\n",
    "        key = path.split(bucket + \"/\")[1]\n",
    "\n",
    "        get_params = {\n",
    "            'Bucket': bucket,\n",
    "            'Key': key\n",
    "        }\n",
    "        response = s3.get_object(**get_params)\n",
    "        stream = response['Body']\n",
    "        reader = csv.DictReader(stream.read().decode('utf-8').splitlines())\n",
    "        json_data = list(reader)\n",
    "        \n",
    "        return json_data\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59865809",
   "metadata": {},
   "source": [
    "# Condiciones - Logica para extraer condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = []\n",
    "\n",
    "def get_correct_value_type(value, value_type):\n",
    "    if value_type == 'BOOLEAN':\n",
    "        if value == 'true' or value == True:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif value_type == 'NUMBER':\n",
    "        if value == None or value == '' or value == 'undefined' or isNaN(value):\n",
    "            value = 0\n",
    "        return float(value)\n",
    "    elif value_type == 'DATE':\n",
    "        return datetime.strptime(value, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "def get_value(field_type, field, value_type, user_data = {}):\n",
    "    if field_type == 'CUSTOMER_PROFILE':\n",
    "        return get_correct_value_type(user_data[field], value_type)\n",
    "    elif field_type == 'CONTEXT_VARIABLE':\n",
    "        return get_correct_value_type(variables[field], value_type)\n",
    "    else:\n",
    "        return get_correct_value_type(field, value_type)\n",
    "\n",
    "def evaluate(condition, user_data = {}):\n",
    "    condition_value = 0\n",
    "    upper = 0\n",
    "    lower = 0\n",
    "    value = get_value(condition['fieldType'], condition['field'], condition['valueType'], user_data)\n",
    "\n",
    "    if condition['operator'] == 'BETWEEN':\n",
    "        values = condition['value'].split(',')\n",
    "        upper = get_correct_value_type(values[1], condition['valueType'])\n",
    "        lower = get_correct_value_type(values[0], condition['valueType'])\n",
    "    else:\n",
    "        condition_value = get_value(condition['source'], condition['value'], condition['valueType'], user_data)\n",
    "\n",
    "    operator = condition['operator']\n",
    "    if operator == 'EQUALS' or operator == '==':\n",
    "        return condition_value == value\n",
    "    elif operator == 'IN' or operator == 'in':\n",
    "        return value in condition_value\n",
    "    elif operator == 'NOT_EQUALS' or operator == '!=':\n",
    "        return condition_value != value\n",
    "    elif operator == 'GREATER_THAN' or operator == '>':\n",
    "        return value > condition_value\n",
    "    elif operator == 'LESS_THAN' or operator == '<':\n",
    "        return value < condition_value\n",
    "    elif operator == 'GREATER_THAN_OR_EQUAL' or operator == '>=':\n",
    "        return value >= condition_value\n",
    "    elif operator == 'LESS_THAN_OR_EQUAL' or operator == '<=':\n",
    "        return value <= condition_value\n",
    "    elif operator == 'BETWEEN':\n",
    "        return lower <= value <= upper\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def evaluate_conditions(condition_groups, user_data, _variables):\n",
    "    global variables\n",
    "    variables = _variables\n",
    "\n",
    "    if condition_groups and len(condition_groups) == 0:\n",
    "        return True\n",
    "\n",
    "    conditions_true = False\n",
    "    results_groups = []\n",
    "\n",
    "    for condition_group in condition_groups:\n",
    "        group_true = True\n",
    "        for condition in condition_group:\n",
    "            evaluated = evaluate(condition, user_data)\n",
    "            if not evaluated:\n",
    "                group_true = False\n",
    "                break\n",
    "        results_groups.append(group_true)\n",
    "\n",
    "    for result in results_groups:\n",
    "        if result:\n",
    "            conditions_true = True\n",
    "            break\n",
    "\n",
    "    return conditions_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c3471",
   "metadata": {},
   "source": [
    "# S3 File - Logica para extraer Resultados Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d29766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_megabytes_size(data):\n",
    "    json_string = json.dumps(data)\n",
    "    size = len(json_string.encode())\n",
    "    kilo_bytes = size / 1024\n",
    "    mega_bytes = kilo_bytes / 1024\n",
    "    return mega_bytes\n",
    "\n",
    "async def get_result_data(results, name):\n",
    "    mega_bytes = get_megabytes_size(results)\n",
    "\n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        filename = f\"{name.replace(' ', '_')}_{int(time.time())}.json\"\n",
    "        params = {\n",
    "            'Bucket': 'amplify-segmentationruleapi-dev-84649-deployment/evaluation-results',\n",
    "            'Key': filename,\n",
    "            'Body': json.dumps(results),\n",
    "            'Expires': 60 * 60\n",
    "        }\n",
    "        await s3.put_object(**params)\n",
    "\n",
    "        if mega_bytes > 5:\n",
    "            return {\n",
    "                'results': results[:200],\n",
    "                'message': 'Data size is greater than 4MB and has been saved in S3, you can see a preview in the results',\n",
    "                'stored': True,\n",
    "                'link': f'https://amplify-segmentationruleapi-dev-84649-deployment/evaluation-results/{filename}'\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'results': results,\n",
    "                'message': 'Data size is less than 4MB you can see the results',\n",
    "                'stored': True,\n",
    "                'link': f'https://amplify-segmentationruleapi-dev-84649-deployment/evaluation-results/{filename}'\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'results': [],\n",
    "            'message': str(e) or 'Error saving data in S3',\n",
    "            'stored': True\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f7731",
   "metadata": {},
   "source": [
    "# Querys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_dynamo(condition, user_data={}):\n",
    "    upper = 0\n",
    "    lower = 0\n",
    "    value = ''\n",
    "    if condition['operator'] == 'BETWEEN':\n",
    "        values = condition['value'].split(',')\n",
    "        upper = get_correct_value_type(values[1], condition['valueType'])\n",
    "        lower = get_correct_value_type(values[0], condition['valueType'])\n",
    "    else:\n",
    "        value = get_value(condition['source'], condition['value'], condition['valueType'], user_data)\n",
    "\n",
    "    if condition['valueType'] == \"BOOLEAN\":\n",
    "        value = \"true\" if value else \"false\"\n",
    "\n",
    "    query_value = str(value) if condition['valueType'] == \"STRING\" else value\n",
    "\n",
    "    operator = condition['operator']\n",
    "\n",
    "    if operator == \"BETWEEN\":\n",
    "        return f\"{lower} AND {upper}\"\n",
    "    else:\n",
    "        return query_value\n",
    "\n",
    "def get_operator_dynamo(operator):\n",
    "    if operator in [\"EQUALS\", \"==\"]:\n",
    "        return \"=\"\n",
    "    elif operator in [\"NOT_EQUALS\", \"!=\"]:\n",
    "        return \"<>\"\n",
    "    elif operator in [\"GREATER_THAN\", \">\"]:\n",
    "        return \">\"\n",
    "    elif operator in [\"LESS_THAN\", \"<\"]:\n",
    "        return \"<\"\n",
    "    elif operator in [\"GREATER_THAN_OR_EQUAL\", \">=\"]:\n",
    "        return \">=\"\n",
    "    elif operator in [\"LESS_THAN_OR_EQUAL\", \"<=\"]:\n",
    "        return \"<=\"\n",
    "    elif operator == \"BETWEEN\":\n",
    "        return \"BETWEEN\"\n",
    "    else:\n",
    "        return \"=\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58210aae",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a740316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def build_expression_attribute_values(conditions, user_data):\n",
    "    attribute_values = {}\n",
    "\n",
    "    for condition in conditions:\n",
    "        for sub_condition in condition:\n",
    "            field = sub_condition['field']\n",
    "            query_value = get_query_dynamo(sub_condition, user_data)\n",
    "            expression_value = f':{field.replace(\".\", \"_\")}'\n",
    "            attribute_values[expression_value] = query_value\n",
    "\n",
    "    return attribute_values\n",
    "\n",
    "def build_filter_expression(conditions):\n",
    "    expressions = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        sub_expressions = []\n",
    "\n",
    "        for sub_condition in condition:\n",
    "            field = sub_condition['field']\n",
    "            operator = sub_condition['operator']\n",
    "            expression_key = f'#{field.replace(\".\", \"_\")}'\n",
    "            expression_value = f':{field.replace(\".\", \"_\")}'\n",
    "            sub_expressions.append(f'{expression_key} {get_operator_dynamo(operator)} {expression_value}')\n",
    "\n",
    "        expressions.append(f'({\" AND \".join(sub_expressions)})')\n",
    "\n",
    "    return ' OR '.join(expressions)\n",
    "\n",
    "def build_expression_attribute_names(conditions):\n",
    "    attribute_names = {}\n",
    "\n",
    "    for condition in conditions:\n",
    "        for sub_condition in condition:\n",
    "            field = sub_condition['field']\n",
    "            expression_key = f'#{field.replace(\".\", \"_\")}'\n",
    "            attribute_names[expression_key] = field\n",
    "\n",
    "    return attribute_names\n",
    "\n",
    "async def get_products(table_name, product_type, conditions, limit_outputs, user_data):\n",
    "    dynamodb = boto3.client('dynamodb', region_name='us-east-1')\n",
    "\n",
    "    exp1 = build_filter_expression(conditions)\n",
    "    exp2 = build_expression_attribute_values(conditions, user_data)\n",
    "    exp3 = build_expression_attribute_names(conditions)\n",
    "\n",
    "    exp1 = f\"#type = :type AND {exp1}\"\n",
    "    exp2[':type'] = product_type\n",
    "    exp3['#type'] = 'type'\n",
    "\n",
    "    params = {\n",
    "        'TableName': table_name,\n",
    "        'FilterExpression': exp1,\n",
    "        'ExpressionAttributeValues': exp2,\n",
    "        'ExpressionAttributeNames': exp3\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = await dynamodb.scan(**params)\n",
    "        return response['Items']\n",
    "    except Exception as err:\n",
    "        return {'error': str(err), 'products': []}\n",
    "\n",
    "async def evaluate_output(outputs, user_data):\n",
    "    results = []\n",
    "\n",
    "    if len(outputs) == 0:\n",
    "        return results\n",
    "\n",
    "    for output in outputs:\n",
    "        limit = output['limit']\n",
    "        priority = output['priority']\n",
    "        result_out = await get_products('srProductCatalogue', output['catalogue'], output['conditions'], limit, user_data)\n",
    "        if result_out and len(result_out) > 0:\n",
    "            results.append({'resultOut': result_out, 'priority': priority})\n",
    "\n",
    "    results.sort(key=lambda x: x['priority'])\n",
    "    results = [r['resultOut'] for r in results]\n",
    "    random.shuffle(results)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40537b73",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfaed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def evaluate_sresf(tree, context_variables={}, filter_users=[]):\n",
    "    results = []\n",
    "    settings = tree['settings']\n",
    "    no_outputs = next((element for element in settings if element['key'] == 'no_outputs'), None)\n",
    "    tree_metrics = tree['metrics']\n",
    "    variables = json.loads(context_variables) if context_variables else {}\n",
    "\n",
    "    if filter_users:\n",
    "        for index, user_info in enumerate(filter_users):\n",
    "            user_data = user_info\n",
    "            result = await evaluate_nodes(tree['nodes'], user_data)\n",
    "            user = user_info['msisdn']\n",
    "            result_outputs = result['outputs']\n",
    "            metrics = await get_metrics(tree_metrics, user_data)\n",
    "\n",
    "            if result_outputs:\n",
    "                outputs = await check_settings(result_outputs, settings)\n",
    "                results.append({'user': user, 'outputs': outputs, 'metrics': metrics})\n",
    "            elif no_outputs and no_outputs['value']:\n",
    "                outputs = []\n",
    "                results.append({'user': user, 'outputs': outputs, 'metrics': metrics})\n",
    "\n",
    "    random.shuffle(results)\n",
    "    data_result = await get_result_data(results)\n",
    "\n",
    "    return data_result\n",
    "\n",
    "\n",
    "async def evaluate_nodes(nodes, user_data, exclusive=False):\n",
    "    results = {'paths': [], 'outputs': []}\n",
    "\n",
    "    if not nodes:\n",
    "        return results\n",
    "\n",
    "    for node in nodes:\n",
    "        if not node['enable']:\n",
    "            continue\n",
    "\n",
    "        node_result = {'paths': [], 'outputs': []}\n",
    "\n",
    "        if evaluate_conditions(node['conditions'], user_data, variables):\n",
    "            node_result['paths'].append(node['description'])\n",
    "\n",
    "            if node['output']:\n",
    "                output_result = await evaluate_output(node['outputs'], user_data)\n",
    "                node_result['outputs'].extend(output_result)\n",
    "\n",
    "            if node['nodes'] and len(node['nodes']) > 0:\n",
    "                child_result = await evaluate_nodes(node['nodes'], user_data, node['exclusive'])\n",
    "                node_result['paths'].extend(child_result['paths'])\n",
    "                node_result['outputs'].extend(child_result['outputs'])\n",
    "\n",
    "            results['paths'].append(node_result['paths'])\n",
    "            results['outputs'].extend(node_result['outputs'])\n",
    "\n",
    "            if exclusive:\n",
    "                break\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
